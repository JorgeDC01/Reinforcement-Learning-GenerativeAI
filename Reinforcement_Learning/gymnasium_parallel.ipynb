{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prueba lunar lander por humano\n",
    "\n",
    "import gymnasium as gym\n",
    "\n",
    "env = gym.make(\"LunarLander-v3\", render_mode=\"rgb_array\")\n",
    "\n",
    "import numpy as np\n",
    "import pygame\n",
    "import gymnasium.utils.play\n",
    "\n",
    "lunar_lander_keys = {\n",
    "    (pygame.K_UP,): 2,\n",
    "    (pygame.K_LEFT,): 1,\n",
    "    (pygame.K_RIGHT,): 3,\n",
    "}\n",
    "# gymnasium.utils.play.play(env, zoom=3, keys_to_action=lunar_lander_keys, noop=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba 1. AG - Evoluci贸n generacional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tareas\n",
    "1. Probar nuevas politicas\n",
    "2. Nuevos operadores: crossover, mutacion\n",
    "3. Cambio de arquitectura [8, X, 4]. 2,6,20\n",
    "4. Graficas: \n",
    "    - mejor fitness en funcion de generaciones\n",
    "    - fitness medio (de poblacion) en funcion de generaciones\n",
    "    - Precision (numero de aterrizajes correctos en cada iteracion) // hay que obtener \"algun indicativo de que aterrice bien\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MLP import MLP\n",
    "import random\n",
    "\n",
    "def policy_base (observation, model):\n",
    "    s = model.forward(observation)\n",
    "    action = np.argmax(s)\n",
    "    return action\n",
    "\n",
    "def policy_epsGreedy(observation, model):\n",
    "    epsilon = 0.10\n",
    "    s = model.forward(observation)\n",
    "    if np.random.rand() < epsilon:\n",
    "        action = np.random.randint(len(s))\n",
    "    else:\n",
    "        action = np.argmax(s)\n",
    "    return action\n",
    "\n",
    "def run (model):\n",
    "    #observation, info = env.reset(seed=42)\n",
    "    observation, info = env.reset()\n",
    "    ite = 0\n",
    "    racum = 0\n",
    "    while True:\n",
    "        action = policy_epsGreedy(observation, model)\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        \n",
    "        racum += reward\n",
    "\n",
    "        if terminated or truncated:\n",
    "            #r = (racum+200) / 500\n",
    "            #print(racum, r)\n",
    "            return racum\n",
    "\n",
    "\n",
    "def run_multiple_games(ch, arquitecture, N_games):\n",
    "\n",
    "    model = MLP(arquitecture)\n",
    "    model.from_chromosome(ch)\n",
    "\n",
    "    r = 0\n",
    "\n",
    "    for _ in range(N_games):\n",
    "        r += run(model)\n",
    "    \n",
    "    return r/N_games # devuelve el refuerzo medio\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define operadores de n煤meros reales\n",
    "import loky\n",
    "from loky import get_reusable_executor\n",
    "import itertools\n",
    "\n",
    "rang = (-1, 1) # al no hacerlo con clases, debemos definir el rango como variable global\n",
    "\n",
    "\n",
    "def select(pop, T, fitness_array): \n",
    "    tournament = random.sample(range(len(pop)), T)  \n",
    "    # Busca el 铆ndice del mejor individuo (mayor fitness porque es acumulativo en LunarLander)\n",
    "    best_index = max(tournament, key=lambda i: fitness_array[i])  \n",
    "    return pop[best_index].copy()  \n",
    "\n",
    "\n",
    "def create(arquitecture, N=100): \n",
    "    pop = []\n",
    "\n",
    "    cromosoma_length = (arquitecture[0] * arquitecture[1]) + arquitecture[1] + (arquitecture[1] * arquitecture[2]) + arquitecture[2]\n",
    "\n",
    "    for _ in range(N):\n",
    "        values = [random.uniform(-5, 5) for _ in range(cromosoma_length)]  \n",
    "        pop.append(values)\n",
    "\n",
    "    return pop\n",
    "\n",
    "\n",
    "def sort_pop (pop, fitness): \n",
    "    pop_with_fitness = [(indiv, fit) for indiv, fit in zip(pop, fitness)]\n",
    "    sorted_pop = sorted(pop_with_fitness, key=lambda x: x[1], reverse=True)  # Mayor fitness primero\n",
    "    return [indiv for indiv, _ in sorted_pop], [fit for _, fit in sorted_pop]\n",
    "\n",
    "\n",
    "def crossover (ind1, ind2, pcross, arquitecture): # devuelve el cruce (emparejamiento) de dos individuos, considerando todos los genes\n",
    "    if (random.random() > pcross):\n",
    "        return ind1.copy(), ind2.copy()\n",
    "    child1 = []\n",
    "    child2 = []\n",
    "\n",
    "    for gene1, gene2 in zip(ind1, ind2):\n",
    "        beta = random.uniform(0, 1)\n",
    "        c1 = beta * gene1 + (1 - beta) * gene2\n",
    "        c2 = (1 - beta) * gene1 + beta * gene2\n",
    "        \n",
    "        child1.append(c1)\n",
    "        child2.append(c2)\n",
    "    \n",
    "    return child1, child2\n",
    "    \n",
    "\n",
    "def mutate(ind, pmut):\n",
    "    if random.random() < pmut:\n",
    "        idx = random.randint(0, len(ind) - 1)\n",
    "        ind[idx] = random.uniform(rang[0], rang[1])\n",
    "    return ind.copy()\n",
    "\n",
    "\n",
    "\n",
    "def evolve_gen(pop, pmut, arquitecture = [8,6,4], generations = 6000, T=2, trace=100, pcross=0.7, elitism=False, N_games=2):\n",
    "    \n",
    "    generation = 0\n",
    "    executor = get_reusable_executor(max_workers=8, timeout=2)\n",
    "\n",
    "    \n",
    "    while generation < generations:\n",
    "        new_poblacion = []\n",
    "\n",
    "        fitness_array = list(executor.map(run_multiple_games, pop, itertools.repeat(arquitecture), itertools.repeat(N_games)))\n",
    "        generation += 1\n",
    "        \n",
    "        pop, fitness = sort_pop(pop, fitness_array)\n",
    "\n",
    "        if trace > 0 and generation % trace == 0:\n",
    "            print(f\"Generacion: {generation}, Mejor fitness: {fitness[0]}\")\n",
    "\n",
    "        if elitism:\n",
    "            new_poblacion.append(pop[0].copy())\n",
    "\n",
    "        if generation >= generations:\n",
    "            break\n",
    "\n",
    "\n",
    "        while len(new_poblacion) < len(pop):\n",
    "            parent_1 = select(pop, T, fitness)\n",
    "            parent_2 = select(pop, T, fitness)\n",
    "\n",
    "            child_1, child_2 = crossover(parent_1, parent_2, pcross, arquitecture)\n",
    "\n",
    "            child_1 = mutate(child_1, pmut)\n",
    "            child_2 = mutate(child_2, pmut)\n",
    "\n",
    "            new_poblacion.extend([child_1, child_2])\n",
    "\n",
    "        pop = new_poblacion[:len(pop)].copy()\n",
    "\n",
    "    print(f\"Generacion: {generation}, Mejor fitness: {fitness[0]}\")\n",
    "    return pop, fitness\n",
    "\n",
    "\n",
    "def evolve_evals(pop, pmut, arquitecture = [8,6,4], neval = 3500, T=2, trace=100, pcross=0.7, elitism=False, N_games=2):\n",
    "    \"\"\"\n",
    "    Algoritmo evolutivo con traza basada en el n煤mero de evaluaciones.\n",
    "    \"\"\"\n",
    "    evaluaciones = 0\n",
    "    executor = get_reusable_executor(max_workers=1, timeout=2)\n",
    "    \n",
    "    \n",
    "    while evaluaciones < neval:\n",
    "\n",
    "        new_poblacion = []\n",
    "\n",
    "        fitness_array = list(executor.map(run_multiple_games, pop, itertools.repeat(arquitecture), itertools.repeat(N_games)))\n",
    "        evaluaciones += N_games*len(pop)\n",
    "\n",
    "        pop, fitness = sort_pop(pop, fitness_array)\n",
    "\n",
    "        if trace > 0 and evaluaciones % trace == 0:\n",
    "            print(f\"Evaluaciones: {evaluaciones}, Mejor fitness: {fitness[0]}\")\n",
    "\n",
    "        if elitism:\n",
    "            new_poblacion.append(pop[0].copy())\n",
    "\n",
    "        if evaluaciones >= neval:\n",
    "            break\n",
    "\n",
    "        while len(new_poblacion) < len(pop):\n",
    "            parent_1 = select(pop, T, fitness)\n",
    "            parent_2 = select(pop, T, fitness)\n",
    "\n",
    "            child_1, child_2 = crossover(parent_1, parent_2, pcross, arquitecture)\n",
    "\n",
    "            child_1 = mutate(child_1, pmut)\n",
    "            child_2 = mutate(child_2, pmut)\n",
    "\n",
    "            new_poblacion.extend([child_1, child_2])\n",
    "\n",
    "        # Actualiza nueva poblacion\n",
    "        pop = new_poblacion[:len(pop)].copy()\n",
    "\n",
    "    print(f\"Evaluaciones: {evaluaciones}, Mejor fitness: {fitness[0]}\")\n",
    "    return pop, fitness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "print(multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejecuci贸n 1\n",
      "Generacion: 50, Mejor fitness: -256.04323938154914\n",
      "Generacion: 100, Mejor fitness: -227.83518193034425\n",
      "Generacion: 150, Mejor fitness: -298.1898802799158\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEjecuci贸n \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m pop \u001b[38;5;241m=\u001b[39m create(arquitecture\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m4\u001b[39m])\n\u001b[1;32m----> 9\u001b[0m pop, fitness \u001b[38;5;241m=\u001b[39m evolve_gen(pop, pmut\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, arquitecture\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m4\u001b[39m], generations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, T\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, trace\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, pcross\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m, elitism\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, N_games\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# 1000 gen = 1000 * 100 * 2 = \u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#pop, fitness = evolve_evals(pop, pmut=0.1, arquitecture=[8,6,4], neval=2000, T=4, trace=1, pcross=0.7, elitism=True, N_games=2)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m best_individual \u001b[38;5;241m=\u001b[39m pop[\u001b[38;5;241m0\u001b[39m]  \n",
      "Cell \u001b[1;32mIn[3], line 68\u001b[0m, in \u001b[0;36mevolve_gen\u001b[1;34m(pop, pmut, arquitecture, generations, T, trace, pcross, elitism, N_games)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m generation \u001b[38;5;241m<\u001b[39m generations:\n\u001b[0;32m     66\u001b[0m     new_poblacion \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 68\u001b[0m     fitness_array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(executor\u001b[38;5;241m.\u001b[39mmap(run_multiple_games, pop, itertools\u001b[38;5;241m.\u001b[39mrepeat(arquitecture), itertools\u001b[38;5;241m.\u001b[39mrepeat(N_games)))\n\u001b[0;32m     69\u001b[0m     generation \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     71\u001b[0m     pop, fitness \u001b[38;5;241m=\u001b[39m sort_pop(pop, fitness_array)\n",
      "File \u001b[1;32mc:\\Users\\34627\\anaconda3\\Lib\\site-packages\\loky\\process_executor.py:967\u001b[0m, in \u001b[0;36m_chain_from_iterable_of_lists\u001b[1;34m(iterable)\u001b[0m\n\u001b[0;32m    961\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_chain_from_iterable_of_lists\u001b[39m(iterable):\n\u001b[0;32m    962\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    963\u001b[0m \u001b[38;5;124;03m    Specialized implementation of itertools.chain.from_iterable.\u001b[39;00m\n\u001b[0;32m    964\u001b[0m \u001b[38;5;124;03m    Each item in *iterable* should be a list.  This function is\u001b[39;00m\n\u001b[0;32m    965\u001b[0m \u001b[38;5;124;03m    careful not to keep references to yielded objects.\u001b[39;00m\n\u001b[0;32m    966\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 967\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m    968\u001b[0m         element\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[0;32m    969\u001b[0m         \u001b[38;5;28;01mwhile\u001b[39;00m element:\n",
      "File \u001b[1;32mc:\\Users\\34627\\anaconda3\\Lib\\concurrent\\futures\\_base.py:619\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[1;34m()\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[0;32m    618\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 619\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs\u001b[38;5;241m.\u001b[39mpop())\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    621\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs\u001b[38;5;241m.\u001b[39mpop(), end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[1;32mc:\\Users\\34627\\anaconda3\\Lib\\concurrent\\futures\\_base.py:317\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 317\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fut\u001b[38;5;241m.\u001b[39mresult(timeout)\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m         fut\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[1;32mc:\\Users\\34627\\anaconda3\\Lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Users\\34627\\anaconda3\\Lib\\threading.py:355\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    354\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 355\u001b[0m         waiter\u001b[38;5;241m.\u001b[39macquire()\n\u001b[0;32m    356\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    357\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# crea y evoluiona\n",
    "best_individuals = []\n",
    "himmelblau_values = []\n",
    "fitness_values = []\n",
    "\n",
    "for i in range(1,2):\n",
    "    print(f\"Ejecuci贸n {i}\")\n",
    "    pop = create(arquitecture=[8,6,4]) \n",
    "    # CAMBIO DE T a 4 y n_games a 1\n",
    "    pop, fitness = evolve_gen(pop, pmut=0.1, arquitecture=[8,6,4], generations=500, T=4, trace=50, pcross=0.7, elitism=False, N_games=1)\n",
    "    # 1000 gen = 1000 * 100 * 2 = \n",
    "    #pop, fitness = evolve_evals(pop, pmut=0.1, arquitecture=[8,6,4], neval=2000, T=4, trace=1, pcross=0.7, elitism=True, N_games=2)\n",
    "    best_individual = pop[0]  \n",
    "    fitness_value = fitness[0]\n",
    "\n",
    "    # Almacenar resultados\n",
    "    best_individuals.append(best_individual)\n",
    "    fitness_values.append(fitness_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward: -33.465313386058796\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def run_lunar_lander(model, chromosome):\n",
    "\n",
    "    env = gym.make(\"LunarLander-v3\", render_mode=\"human\")  \n",
    "    observation, _ = env.reset() \n",
    "    model.from_chromosome(chromosome)  \n",
    "    \n",
    "    total_reward = 0\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        env.render()  \n",
    "        \n",
    "        action_values = model.forward(observation)  \n",
    "        action = np.argmax(action_values)  \n",
    "        \n",
    "        observation, reward, done, _, _ = env.step(action)  \n",
    "        total_reward += reward\n",
    "        \n",
    "        time.sleep(0.05)  \n",
    "    \n",
    "    env.close()\n",
    "    print(f\"Total reward: {total_reward}\")\n",
    "\n",
    "arquitecture = [8, 6, 4] \n",
    "model = MLP(arquitecture)\n",
    "\n",
    "\n",
    "#  Ejecutar el modelo en el entorno\n",
    "run_lunar_lander(model, best_individuals[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "fitness_mean = np.mean(fitness_values)\n",
    "fitness_std = np.std(fitness_values)\n",
    "\n",
    "\n",
    "best_ind_index = np.argmax(fitness_values)\n",
    "best_ind = best_individuals[best_ind_index]\n",
    "best_fitness = fitness_values[best_ind_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media de fitness: 0.9425973798932168\n",
      "Desviaci贸n t铆pica de fitness: 0.0832002599174057\n",
      "-----\n",
      "Media de himmelblau: 0.07014512890659286\n",
      "Desviaci贸n t铆pica de himmelblau: 0.10485796294344779\n",
      "-----\n",
      "El mejor individuo es [3.000423765860462, 2.0033795362969467]\n",
      "Fitness en ese individuo: 0.9997702835\n",
      "Himmelblau de la mejor soluci贸n: 0.0002297693\n"
     ]
    }
   ],
   "source": [
    "print(f\"Media de fitness: {fitness_mean}\")\n",
    "print(f\"Desviaci贸n t铆pica de fitness: {fitness_std}\")\n",
    "\n",
    "print (\"-----\")\n",
    "\n",
    "print(f\"El mejor individuo es {best_ind}\")\n",
    "print(f\"Fitness en ese individuo: {best_fitness:.10f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generacion 0: mejor fitness [0.2952568997016495]\n",
      "Generacion 25: mejor fitness [0.838982892859534]\n",
      "Generacion 50: mejor fitness [0.838982892859524]\n",
      "Generacion 75: mejor fitness [0.8389828928595396]\n",
      "Generacion 100: mejor fitness [0.8389828928595421]\n"
     ]
    }
   ],
   "source": [
    "# crea y evoluiona\n",
    "pop = create()\n",
    "pop, fitness = evolve(pop, arquitecture = [8,6,4], pmut=10/100, ngen=100, T=4, trace=25, pcross=0.7, elitism=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El mejor individuo es [3.531729179447823, -1.77507053290786]\n",
      "Valor de la funci贸n de Himmelblau en ese individuo: 0.1919194164\n",
      "Fitness de la mejor soluci贸n: 0.8389828928595421\n"
     ]
    }
   ],
   "source": [
    "# Mejor individuo, valor en la funci贸n y su fitness\n",
    "best_individual = pop[0]\n",
    "fitness_best = fitness[0]\n",
    "  \n",
    "\n",
    "print(f\"El mejor individuo es {best_individual}\")\n",
    "print(f\"Fitness de la mejor soluci贸n: {fitness_best}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
