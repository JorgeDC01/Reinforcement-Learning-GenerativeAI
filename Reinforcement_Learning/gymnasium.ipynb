{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prueba lunar lander por humano\n",
    "\n",
    "import gymnasium as gym\n",
    "\n",
    "env = gym.make(\"LunarLander-v3\", render_mode=\"rgb_array\")\n",
    "\n",
    "import numpy as np\n",
    "import pygame\n",
    "import gymnasium.utils.play\n",
    "\n",
    "lunar_lander_keys = {\n",
    "    (pygame.K_UP,): 2,\n",
    "    (pygame.K_LEFT,): 1,\n",
    "    (pygame.K_RIGHT,): 3,\n",
    "}\n",
    "gymnasium.utils.play.play(env, zoom=3, keys_to_action=lunar_lander_keys, noop=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba 1. AG - Evoluci贸n generacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MLP import MLP\n",
    "import random\n",
    "\n",
    "\n",
    "def policy (observation, model):\n",
    "    s = model.forward(observation)\n",
    "    action = np.argmax(s)\n",
    "    return action\n",
    "\n",
    "evaluaciones = 0\n",
    "\n",
    "def run (model):\n",
    "    #observation, info = env.reset(seed=42)\n",
    "    observation, info = env.reset()\n",
    "    ite = 0\n",
    "    racum = 0\n",
    "    while True:\n",
    "        action = policy(observation, model)\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        \n",
    "        racum += reward\n",
    "\n",
    "        if terminated or truncated:\n",
    "            r = (racum+200) / 500\n",
    "            #print(racum, r)\n",
    "            return racum\n",
    "\n",
    "\n",
    "def run_multiple_games(ch, model, N_games):\n",
    "    global evaluaciones\n",
    "    model.from_chromosome(ch)\n",
    "    r = 0\n",
    "\n",
    "    for _ in range(N_games):\n",
    "        r += run(model)\n",
    "        evaluaciones += 1\n",
    "    \n",
    "    return r/N_games, ch # devuelve el refuerzo medio\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define operadores de n煤meros reales\n",
    "\n",
    "rang = (-1, 1) # al no hacerlo con clases, debemos definir el rango como variable global\n",
    "\n",
    "\n",
    "'''\n",
    "    Devuelve un individuo seleccionado por torneo. Se selecciona el individuo de mayor fitness sobre un \n",
    "    conjunto aleatorio equiprobable T.\n",
    "'''\n",
    "\n",
    "def select(pop, T, fitness_array): \n",
    "    tournament = random.sample(range(len(pop)), T)  \n",
    "    # Busca el 铆ndice del mejor individuo (mayor fitness porque es acumulativo en LunarLander)\n",
    "    best_index = max(tournament, key=lambda i: fitness_array[i])  \n",
    "    return pop[best_index].copy()  \n",
    "\n",
    "\n",
    "def create(arquitecture, N=100): \n",
    "    pop = []\n",
    "\n",
    "    cromosoma_length = (arquitecture[0] * arquitecture[1]) + arquitecture[1] + (arquitecture[1] * arquitecture[2]) + arquitecture[2]\n",
    "\n",
    "    for _ in range(N):\n",
    "        values = [random.uniform(-1, 1) for _ in range(cromosoma_length)]  \n",
    "        pop.append(values)\n",
    "\n",
    "   \n",
    "    return pop\n",
    "\n",
    "'''\n",
    "    Funci贸n que ordena una poblacion segun el fitness.\n",
    "    @return: Devuelve la poblacion ordenada por fitness, y los valores fitness de cada individuo de la poblacion.\n",
    "'''\n",
    "def sort_pop (pop, fitness): \n",
    "    pop_with_fitness = [(indiv, fit) for indiv, fit in zip(pop, fitness)]\n",
    "    sorted_pop = sorted(pop_with_fitness, key=lambda x: x[1], reverse=True)  # Mayor fitness primero\n",
    "    return [indiv for indiv, _ in sorted_pop], [fit for _, fit in sorted_pop]\n",
    "\n",
    "'''\n",
    "    Funcion que implementa el operador crossover: emparejamiento de dos individuos. pcross: probabilidad de que \n",
    "    se produzca el emparejamiento. Se implementa el emparejamiento para n煤meros reales basado en una combinacion\n",
    "    de los genes de ambos padres. Los genes de cada padre tienen una mayor representacion en uno de los dos hijos.\n",
    "    @return: dos hijos\n",
    "'''\n",
    "# def crossover (ind1, ind2, pcross, arquitecture): # devuelve el cruce (emparejamiento) de dos individuos\n",
    "    \n",
    "#     if (random.random() > pcross):\n",
    "#         return ind1.copy(), ind2.copy()\n",
    "\n",
    "#     beta = random.uniform(0,1)\n",
    "    \n",
    "#     child1_x = beta*ind1[0] + (1 - beta)*ind2[0]\n",
    "#     child1_y = beta*ind1[1] + (1 - beta)*ind2[1]\n",
    "\n",
    "#     child2_x = (1 - beta)*ind1[0] + beta*ind2[0]\n",
    "#     child2_y = (1 - beta)*ind1[1] + beta*ind2[1]\n",
    "\n",
    "\n",
    "#     return [child1_x, child1_y], [child2_x, child2_y]\n",
    "\n",
    "def crossover (ind1, ind2, pcross, arquitecture): # devuelve el cruce (emparejamiento) de dos individuos\n",
    "    if (random.random() > pcross):\n",
    "        return ind1.copy(), ind2.copy()\n",
    "    child1 = []\n",
    "    child2 = []\n",
    "    \n",
    "    for gene1, gene2 in zip(ind1, ind2):\n",
    "        beta = random.random()\n",
    "        \n",
    "        c1 = beta * gene1 + (1 - beta) * gene2\n",
    "        c2 = (1 - beta) * gene1 + beta * gene2\n",
    "        \n",
    "        child1.append(c1)\n",
    "        child2.append(c2)\n",
    "    \n",
    "    return child1, child2\n",
    "    \n",
    "\n",
    "'''\n",
    "    Funci贸n que muta un individuo. pmut: probabilidad de que se produzca la mutacion\n",
    "    Este tipo de mutaci贸n reemplaza uno de los valores en el individuo con un nuevo valor generado\n",
    "    aleatoriamente dentro de los l铆mites definidos (rang).\n",
    "'''\n",
    "def mutate(ind, pmut):\n",
    "    if random.random() < pmut:\n",
    "        idx = random.randint(0, len(ind) - 1)\n",
    "        ind[idx] = random.uniform(rang[0], rang[1])\n",
    "    return ind.copy()\n",
    "\n",
    "\n",
    "'''\n",
    "    Algoritmo de evoluci贸n generacional. Funcionamiento:\n",
    "    1. Ordena la poblaci贸n inicial seg煤n su fitness\n",
    "    2. Itera a trav茅s de un n煤mero dado de evaluaciones (neval)\n",
    "        - Si hay elitismo, guarda el mejor individuo directamente en la nueva poblaci贸n\n",
    "        - Realiza selecci贸n por torneo para elegir padres\n",
    "        - Aplica cruce con probabilidad 'pcross' para generar descendientes\n",
    "        - Aplica mutaci贸n con probabilidad 'pmut' a los descendientes\n",
    "        - Llena la nueva poblaci贸n con los descendientes generados\n",
    "    3. Ordena la nueva poblaci贸n y eval煤a el fitness\n",
    "    4. Imprime el mejor fitness cada 'trace' evaluaciones, si est谩 habilitado\n",
    "    5. Devuelve la mejor poblaci贸n al final de las evaluaciones\n",
    "    @return: poblacion final\n",
    "'''\n",
    "def evolve(pop, pmut, arquitecture, neval=3500, T=2, trace=100, pcross=0.7, elitism=False):\n",
    "    \"\"\"\n",
    "    Algoritmo evolutivo con traza basada en el n煤mero de evaluaciones.\n",
    "    \"\"\"\n",
    "    global evaluaciones\n",
    "    evaluaciones = 0\n",
    "\n",
    "    architecture = [8, 6, 4] # salida = 4; izq, der, arriba y apagado\n",
    "    model = MLP(architecture)\n",
    "    \n",
    "    while evaluaciones < neval:\n",
    "        new_poblacion = []\n",
    "        fitness_array = []\n",
    "        \n",
    "        # -- Se ejecuta el RUN de todos los individuos de la poblacion y nos quedamos con los fitness = rewards\n",
    "        for indv in pop:\n",
    "            fitness_n_games, ch = run_multiple_games(indv, model, 2)\n",
    "            fitness_array.append(fitness_n_games)\n",
    "        \n",
    "        # Genera la nueva poblaci贸n\n",
    "        while len(new_poblacion) < len(pop):\n",
    "            parent_1 = select(pop, T, fitness_array)\n",
    "            parent_2 = select(pop, T, fitness_array)\n",
    "\n",
    "            child_1, child_2 = crossover(parent_1, parent_2, pcross, arquitecture)\n",
    "\n",
    "            child_1 = mutate(child_1, pmut)\n",
    "            child_2 = mutate(child_2, pmut)\n",
    "\n",
    "            new_poblacion.extend([child_1, child_2])\n",
    "\n",
    "            # Verifica el l铆mite de evaluaciones despu茅s de cada operaci贸n relevante\n",
    "            if evaluaciones >= neval:\n",
    "                break\n",
    "\n",
    "        if evaluaciones >= neval:\n",
    "            break\n",
    "\n",
    "        # Ordena la nueva poblaci贸n y calcula fitness\n",
    "        pop, fitness = sort_pop(new_poblacion[:len(pop)], fitness_array)\n",
    "\n",
    "        if trace > 0 and evaluaciones % trace == 0:\n",
    "            print(f\"Evaluaciones: {evaluaciones}, Mejor fitness: {fitness[0]}\")\n",
    "\n",
    "    print(f\"Evaluaciones: {evaluaciones}, Mejor fitness: {fitness[0]}\")\n",
    "    return pop, fitness\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decisiones\n",
    "\n",
    "**Operadores b谩sicos**:\n",
    "- Selecci贸n: por torneo\n",
    "- Emparejamiento: mezclado lineal \n",
    "- Mutaci贸n: por rango [vmin, vmax]\n",
    "\n",
    "**Hiperpar谩metros**:\n",
    "* *pmut*: 10/100\n",
    "* *ngen*: 100\n",
    "* T: 4\n",
    "* *pcross*: 0.7\n",
    "* elisitm: False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejecuci贸n 1\n",
      "Evaluaciones: 200, Mejor fitness: -45.83686654596207\n",
      "Evaluaciones: 400, Mejor fitness: -24.31074955721847\n",
      "Evaluaciones: 600, Mejor fitness: -25.246726662274014\n",
      "Evaluaciones: 800, Mejor fitness: -38.186428229145335\n",
      "Evaluaciones: 1000, Mejor fitness: -38.2385507515295\n",
      "Evaluaciones: 1200, Mejor fitness: -35.13904651328728\n",
      "Evaluaciones: 1400, Mejor fitness: -9.847544901246337\n",
      "Evaluaciones: 1600, Mejor fitness: -15.551566912593522\n",
      "Evaluaciones: 1800, Mejor fitness: -42.34057955666513\n",
      "Evaluaciones: 2000, Mejor fitness: -24.05826282060974\n",
      "Evaluaciones: 2200, Mejor fitness: 54.99716169729059\n",
      "Evaluaciones: 2400, Mejor fitness: -19.64313430415241\n",
      "Evaluaciones: 2600, Mejor fitness: -67.72770453244553\n",
      "Evaluaciones: 2800, Mejor fitness: -30.823735016375025\n",
      "Evaluaciones: 3000, Mejor fitness: -56.90987999249397\n",
      "Evaluaciones: 3200, Mejor fitness: -41.36817252072982\n",
      "Evaluaciones: 3400, Mejor fitness: -31.629973718056718\n",
      "Evaluaciones: 3600, Mejor fitness: -31.629973718056718\n"
     ]
    }
   ],
   "source": [
    "# crea y evoluiona\n",
    "best_individuals = []\n",
    "himmelblau_values = []\n",
    "fitness_values = []\n",
    "\n",
    "for i in range(1,2):\n",
    "    print(f\"Ejecuci贸n {i}\")\n",
    "    pop = create(arquitecture=[8,6,4])\n",
    "    pop, fitness = evolve(pop, arquitecture=[8,6,4], pmut=10/100, neval=3500, T=4, trace=1, pcross=0.7, elitism=False)\n",
    "\n",
    "    best_individual = pop[0]  \n",
    "    fitness_value = fitness[0]\n",
    "\n",
    "    # Almacenar resultados\n",
    "    best_individuals.append(best_individual)\n",
    "    fitness_values.append(fitness_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward: -33.465313386058796\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def run_lunar_lander(model, chromosome):\n",
    "\n",
    "    env = gym.make(\"LunarLander-v3\", render_mode=\"human\")  \n",
    "    observation, _ = env.reset() \n",
    "    model.from_chromosome(chromosome)  \n",
    "    \n",
    "    total_reward = 0\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        env.render()  \n",
    "        \n",
    "        action_values = model.forward(observation)  \n",
    "        action = np.argmax(action_values)  \n",
    "        \n",
    "        observation, reward, done, _, _ = env.step(action)  \n",
    "        total_reward += reward\n",
    "        \n",
    "        time.sleep(0.05)  \n",
    "    \n",
    "    env.close()\n",
    "    print(f\"Total reward: {total_reward}\")\n",
    "\n",
    "arquitecture = [8, 6, 4] \n",
    "model = MLP(arquitecture)\n",
    "\n",
    "\n",
    "#  Ejecutar el modelo en el entorno\n",
    "run_lunar_lander(model, best_individuals[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "fitness_mean = np.mean(fitness_values)\n",
    "fitness_std = np.std(fitness_values)\n",
    "\n",
    "\n",
    "best_ind_index = np.argmax(fitness_values)\n",
    "best_ind = best_individuals[best_ind_index]\n",
    "best_fitness = fitness_values[best_ind_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media de fitness: 0.9425973798932168\n",
      "Desviaci贸n t铆pica de fitness: 0.0832002599174057\n",
      "-----\n",
      "Media de himmelblau: 0.07014512890659286\n",
      "Desviaci贸n t铆pica de himmelblau: 0.10485796294344779\n",
      "-----\n",
      "El mejor individuo es [3.000423765860462, 2.0033795362969467]\n",
      "Fitness en ese individuo: 0.9997702835\n",
      "Himmelblau de la mejor soluci贸n: 0.0002297693\n"
     ]
    }
   ],
   "source": [
    "print(f\"Media de fitness: {fitness_mean}\")\n",
    "print(f\"Desviaci贸n t铆pica de fitness: {fitness_std}\")\n",
    "\n",
    "print (\"-----\")\n",
    "\n",
    "print(f\"El mejor individuo es {best_ind}\")\n",
    "print(f\"Fitness en ese individuo: {best_fitness:.10f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generacion 0: mejor fitness [0.2952568997016495]\n",
      "Generacion 25: mejor fitness [0.838982892859534]\n",
      "Generacion 50: mejor fitness [0.838982892859524]\n",
      "Generacion 75: mejor fitness [0.8389828928595396]\n",
      "Generacion 100: mejor fitness [0.8389828928595421]\n"
     ]
    }
   ],
   "source": [
    "# crea y evoluiona\n",
    "pop = create()\n",
    "pop, fitness = evolve(pop, arquitecture = [8,6,4], pmut=10/100, ngen=100, T=4, trace=25, pcross=0.7, elitism=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El mejor individuo es [3.531729179447823, -1.77507053290786]\n",
      "Valor de la funci贸n de Himmelblau en ese individuo: 0.1919194164\n",
      "Fitness de la mejor soluci贸n: 0.8389828928595421\n"
     ]
    }
   ],
   "source": [
    "# Mejor individuo, valor en la funci贸n y su fitness\n",
    "best_individual = pop[0]\n",
    "fitness_best = fitness[0]\n",
    "  \n",
    "\n",
    "print(f\"El mejor individuo es {best_individual}\")\n",
    "print(f\"Fitness de la mejor soluci贸n: {fitness_best}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
